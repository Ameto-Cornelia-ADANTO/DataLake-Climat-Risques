{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eba17efb-49e2-4f9b-bc1c-c5a6a7b3f364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Chargement des donnÃ©es NOAA Silver...\n",
      "ðŸ“Š DonnÃ©es tempÃ©rature chargÃ©es: 100 enregistrements\n",
      "+-------------------+----------+-----------------+------------------+------------------+----+-----+\n",
      "|               date|station_id|         latitude|         longitude|            temp_c|year|month|\n",
      "+-------------------+----------+-----------------+------------------+------------------+----+-----+\n",
      "|2024-03-16 00:00:00| STATION_0|40.48186609572492|-74.86755597998558| 11.23978774675729|2024|    3|\n",
      "|2024-03-17 00:00:00| STATION_1|41.71198554111676|-74.15738771337645|16.633948794403523|2024|    3|\n",
      "|2024-03-18 00:00:00| STATION_2|41.29907130307006|-74.99322556549149| 18.97464367553694|2024|    3|\n",
      "|2024-03-19 00:00:00| STATION_3|40.97787938028068|-74.75964299884642|17.287862514585633|2024|    3|\n",
      "|2024-03-20 00:00:00| STATION_4|39.91442034663697|-74.24808040111922| 12.29102717093713|2024|    3|\n",
      "+-------------------+----------+-----------------+------------------+------------------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "ðŸ” Calcul des anomalies de tempÃ©rature...\n",
      "ðŸ“ˆ Statistiques des anomalies calculÃ©es:\n",
      "+------------------+-------------------+--------------------+--------------------+----------------------+\n",
      "|            temp_c|avg_temp_historical|        temp_anomaly|       anomaly_score|is_significant_anomaly|\n",
      "+------------------+-------------------+--------------------+--------------------+----------------------+\n",
      "|12.401236070134292| 15.967620398371547| -3.5663843282372554|  1.5903105882779498|                 false|\n",
      "|15.867106088931564| 15.967620398371547|-0.10051430943998341| 0.04482101643118758|                 false|\n",
      "|19.529244067308515| 15.967620398371547|   3.561623668936967|  1.5881877304489467|                 false|\n",
      "|17.461548161640827| 15.967620398371547|    1.49392776326928|  0.6661674461831806|                 false|\n",
      "| 16.09827040678179| 15.967620398371547| 0.13065000841024244|0.058259030045734725|                 false|\n",
      "|14.384150671185091| 15.967620398371547|  -1.583469727186456|  0.7060957097147418|                 false|\n",
      "|16.031787322618744| 15.967620398371547| 0.06416692424719628| 0.02861310774601316|                 false|\n",
      "|13.061560671778102|  16.93173558584062| -3.8701749140625186|  1.5010686308290968|                 false|\n",
      "|17.656153436401887|  16.93173558584062|  0.7244178505612666|  0.2809694484709256|                 false|\n",
      "|18.487208101824525|  16.93173558584062|  1.5554725159839045|  0.6032985722108716|                 false|\n",
      "+------------------+-------------------+--------------------+--------------------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "ðŸ“ Chargement des donnÃ©es USGS Silver...\n",
      "ðŸ“Š DonnÃ©es sismiques chargÃ©es: 50 sÃ©ismes\n",
      "ðŸ”— DonnÃ©es jointes tempÃ©rature-sÃ©ismes\n",
      "\n",
      "ðŸ“Š Analyse des corrÃ©lations...\n",
      "ðŸ“ˆ Coefficients de corrÃ©lation:\n",
      "  â€¢ Anomalie tempÃ©rature vs Nombre sÃ©ismes: -0.228\n",
      "  â€¢ Score anomalie vs Nombre sÃ©ismes: 0.756\n",
      "  â€¢ Anomalie tempÃ©rature vs Magnitude moyenne: 0.379\n",
      "\n",
      "ðŸš¨ Identification des jours Ã  haut risque...\n",
      "ðŸ“‹ Top 10 des jours Ã  haut risque:\n",
      "+----+----------+------------+-------------+----------------+-------------+----------+\n",
      "|date|station_id|temp_anomaly|anomaly_score|earthquake_count|avg_magnitude|risk_score|\n",
      "+----+----------+------------+-------------+----------------+-------------+----------+\n",
      "+----+----------+------------+-------------+----------------+-------------+----------+\n",
      "\n",
      "\n",
      "ðŸ’¾ Sauvegarde des donnÃ©es Gold...\n",
      "âœ… DonnÃ©es Gold sauvegardÃ©es: file:///tmp/gold/anomalies/\n",
      "\n",
      "ðŸŽ‰ === ANALYSE DES ANOMALIES TERMINÃ‰E ===\n",
      "ðŸ“ˆ Anomalies tempÃ©rature: 100 enregistrements\n",
      "ðŸš¨ Jours Ã  haut risque identifiÃ©s: 0\n",
      "\n",
      "ðŸ“Š RÃ‰SUMÃ‰ DES RÃ‰SULTATS:\n",
      "Anomalies de tempÃ©rature:\n",
      "+-------------+--------------------+-----------------+---------------------+\n",
      "|total_records|         avg_anomaly|      std_anomaly|significant_anomalies|\n",
      "+-------------+--------------------+-----------------+---------------------+\n",
      "|          100|4.263256414560601...|2.875317833434375|                    0|\n",
      "+-------------+--------------------+-----------------+---------------------+\n",
      "\n",
      "ActivitÃ© sismique corrÃ©lÃ©e:\n",
      "+-----------------------+-----------------------+-----------------+\n",
      "|avg_earthquakes_per_day|max_earthquakes_per_day|    avg_magnitude|\n",
      "+-----------------------+-----------------------+-----------------+\n",
      "|     16.666666666666668|                     24|3.532284259645982|\n",
      "+-----------------------+-----------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 04_gold_anomalies.ipynb - VERSION CORRIGÃ‰E\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Gold_Anomalies\").getOrCreate()\n",
    "\n",
    "# CORRECTION: Utiliser les chemins locaux\n",
    "BASE_PATH = \"file:///tmp\"\n",
    "SILVER_NOAA = f\"{BASE_PATH}/silver/noaa/\"\n",
    "SILVER_USGS = f\"{BASE_PATH}/silver/usgs/\"\n",
    "GOLD_ANOM = f\"{BASE_PATH}/gold/anomalies/\"\n",
    "\n",
    "# CrÃ©er le rÃ©pertoire de sortie\n",
    "import os\n",
    "os.makedirs(\"/tmp/gold/anomalies\", exist_ok=True)\n",
    "\n",
    "# Charger les donnÃ©es Silver NOAA\n",
    "print(\"ðŸ“ Chargement des donnÃ©es NOAA Silver...\")\n",
    "df_temp = spark.read.parquet(SILVER_NOAA)\n",
    "\n",
    "# Ajouter mois et annÃ©e\n",
    "df_temp = df_temp.withColumn(\"month\", F.month(\"date\")).withColumn(\"year\", F.year(\"date\"))\n",
    "\n",
    "print(f\"ðŸ“Š DonnÃ©es tempÃ©rature chargÃ©es: {df_temp.count()} enregistrements\")\n",
    "df_temp.show(5)\n",
    "\n",
    "# Calcul des anomalies de tempÃ©rature par station\n",
    "print(\"ðŸ” Calcul des anomalies de tempÃ©rature...\")\n",
    "\n",
    "# DÃ©finir la fenÃªtre par station et mois\n",
    "window_spec = Window.partitionBy(\"station_id\", \"month\")\n",
    "\n",
    "# Calculer la moyenne historique et Ã©cart-type par station et mois\n",
    "df_anomalies = df_temp.withColumn(\"avg_temp_historical\", F.avg(\"temp_c\").over(window_spec)) \\\n",
    "                      .withColumn(\"std_temp_historical\", F.stddev(\"temp_c\").over(window_spec))\n",
    "\n",
    "# Calculer l'anomalie (diffÃ©rence par rapport Ã  la moyenne historique)\n",
    "df_anomalies = df_anomalies.withColumn(\"temp_anomaly\", \n",
    "                                       F.col(\"temp_c\") - F.col(\"avg_temp_historical\"))\n",
    "\n",
    "# Identifier les anomalies significatives (> 2 Ã©carts-types)\n",
    "df_anomalies = df_anomalies.withColumn(\n",
    "    \"is_significant_anomaly\",\n",
    "    F.abs(F.col(\"temp_anomaly\")) > (2 * F.col(\"std_temp_historical\"))\n",
    ")\n",
    "\n",
    "# Ajouter un score d'anomalie normalisÃ©\n",
    "df_anomalies = df_anomalies.withColumn(\n",
    "    \"anomaly_score\",\n",
    "    F.when(F.col(\"std_temp_historical\") > 0, \n",
    "           F.abs(F.col(\"temp_anomaly\")) / F.col(\"std_temp_historical\"))\n",
    "     .otherwise(0)\n",
    ")\n",
    "\n",
    "print(\"ðŸ“ˆ Statistiques des anomalies calculÃ©es:\")\n",
    "df_anomalies.select(\"temp_c\", \"avg_temp_historical\", \"temp_anomaly\", \"anomaly_score\", \"is_significant_anomaly\").show(10)\n",
    "\n",
    "# Charger les donnÃ©es USGS pour corrÃ©lation\n",
    "print(\"\\nðŸ“ Chargement des donnÃ©es USGS Silver...\")\n",
    "try:\n",
    "    df_seismic = spark.read.parquet(SILVER_USGS)\n",
    "    print(f\"ðŸ“Š DonnÃ©es sismiques chargÃ©es: {df_seismic.count()} sÃ©ismes\")\n",
    "    \n",
    "    # PrÃ©parer les donnÃ©es sismiques pour jointure\n",
    "    df_seismic_daily = df_seismic.groupBy(\"date\").agg(\n",
    "        F.count(\"*\").alias(\"earthquake_count\"),\n",
    "        F.avg(\"magnitude\").alias(\"avg_magnitude\"),\n",
    "        F.max(\"magnitude\").alias(\"max_magnitude\")\n",
    "    )\n",
    "    \n",
    "    # Jointure avec les anomalies de tempÃ©rature\n",
    "    df_correlation = df_anomalies.join(\n",
    "        df_seismic_daily, \n",
    "        on=\"date\", \n",
    "        how=\"left\"\n",
    "    ).fillna(0, subset=[\"earthquake_count\", \"avg_magnitude\", \"max_magnitude\"])\n",
    "    \n",
    "    print(\"ðŸ”— DonnÃ©es jointes tempÃ©rature-sÃ©ismes\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur chargement USGS: {e}\")\n",
    "    print(\"â„¹ï¸  Utilisation des donnÃ©es tempÃ©rature uniquement\")\n",
    "    df_correlation = df_anomalies\n",
    "\n",
    "# Calcul des corrÃ©lations\n",
    "print(\"\\nðŸ“Š Analyse des corrÃ©lations...\")\n",
    "\n",
    "# CorrÃ©lation entre anomalies de tempÃ©rature et activitÃ© sismique\n",
    "if \"earthquake_count\" in df_correlation.columns:\n",
    "    correlation_stats = df_correlation.filter(F.col(\"earthquake_count\") > 0).agg(\n",
    "        F.corr(\"temp_anomaly\", \"earthquake_count\").alias(\"corr_temp_earthquake_count\"),\n",
    "        F.corr(\"anomaly_score\", \"earthquake_count\").alias(\"corr_score_earthquake_count\"),\n",
    "        F.corr(\"temp_anomaly\", \"avg_magnitude\").alias(\"corr_temp_avg_magnitude\")\n",
    "    ).collect()[0]\n",
    "    \n",
    "    print(\"ðŸ“ˆ Coefficients de corrÃ©lation:\")\n",
    "    print(f\"  â€¢ Anomalie tempÃ©rature vs Nombre sÃ©ismes: {correlation_stats['corr_temp_earthquake_count']:.3f}\")\n",
    "    print(f\"  â€¢ Score anomalie vs Nombre sÃ©ismes: {correlation_stats['corr_score_earthquake_count']:.3f}\")\n",
    "    print(f\"  â€¢ Anomalie tempÃ©rature vs Magnitude moyenne: {correlation_stats['corr_temp_avg_magnitude']:.3f}\")\n",
    "\n",
    "# Identifier les jours Ã  haut risque\n",
    "print(\"\\nðŸš¨ Identification des jours Ã  haut risque...\")\n",
    "\n",
    "df_high_risk = df_correlation.filter(\n",
    "    (F.col(\"is_significant_anomaly\") == True) & \n",
    "    (F.col(\"earthquake_count\") > 0)\n",
    ").withColumn(\"risk_score\", \n",
    "             F.col(\"anomaly_score\") * F.col(\"earthquake_count\") * F.col(\"avg_magnitude\"))\n",
    "\n",
    "# Classer par score de risque\n",
    "df_high_risk_ranked = df_high_risk.orderBy(F.desc(\"risk_score\"))\n",
    "\n",
    "print(\"ðŸ“‹ Top 10 des jours Ã  haut risque:\")\n",
    "df_high_risk_ranked.select(\n",
    "    \"date\", \"station_id\", \"temp_anomaly\", \"anomaly_score\", \n",
    "    \"earthquake_count\", \"avg_magnitude\", \"risk_score\"\n",
    ").show(10)\n",
    "\n",
    "# Sauvegarder les rÃ©sultats Gold\n",
    "print(\"\\nðŸ’¾ Sauvegarde des donnÃ©es Gold...\")\n",
    "\n",
    "# DonnÃ©es d'anomalies dÃ©taillÃ©es\n",
    "df_anomalies.write.mode(\"overwrite\").partitionBy(\"year\").parquet(f\"{GOLD_ANOM}/temperature_anomalies\")\n",
    "\n",
    "# DonnÃ©es de corrÃ©lation et risque\n",
    "df_correlation.write.mode(\"overwrite\").partitionBy(\"year\").parquet(f\"{GOLD_ANOM}/correlation_analysis\")\n",
    "\n",
    "# Top des risques\n",
    "df_high_risk_ranked.write.mode(\"overwrite\").parquet(f\"{GOLD_ANOM}/high_risk_days\")\n",
    "\n",
    "print(f\"âœ… DonnÃ©es Gold sauvegardÃ©es: {GOLD_ANOM}\")\n",
    "\n",
    "# RÃ©sumÃ© final\n",
    "print(\"\\nðŸŽ‰ === ANALYSE DES ANOMALIES TERMINÃ‰E ===\")\n",
    "print(f\"ðŸ“ˆ Anomalies tempÃ©rature: {df_anomalies.count()} enregistrements\")\n",
    "print(f\"ðŸš¨ Jours Ã  haut risque identifiÃ©s: {df_high_risk_ranked.count()}\")\n",
    "\n",
    "if df_high_risk_ranked.count() > 0:\n",
    "    top_risk = df_high_risk_ranked.select(\"date\", \"risk_score\").first()\n",
    "    print(f\"ðŸ“… Jour le plus risquÃ©: {top_risk['date']} (score: {top_risk['risk_score']:.2f})\")\n",
    "\n",
    "# Visualisation des rÃ©sultats\n",
    "print(\"\\nðŸ“Š RÃ‰SUMÃ‰ DES RÃ‰SULTATS:\")\n",
    "print(\"Anomalies de tempÃ©rature:\")\n",
    "df_anomalies.agg(\n",
    "    F.count(\"*\").alias(\"total_records\"),\n",
    "    F.avg(\"temp_anomaly\").alias(\"avg_anomaly\"),\n",
    "    F.stddev(\"temp_anomaly\").alias(\"std_anomaly\"),\n",
    "    F.sum(F.col(\"is_significant_anomaly\").cast(\"int\")).alias(\"significant_anomalies\")\n",
    ").show()\n",
    "\n",
    "if \"earthquake_count\" in df_correlation.columns:\n",
    "    print(\"ActivitÃ© sismique corrÃ©lÃ©e:\")\n",
    "    df_correlation.filter(F.col(\"earthquake_count\") > 0).agg(\n",
    "        F.avg(\"earthquake_count\").alias(\"avg_earthquakes_per_day\"),\n",
    "        F.max(\"earthquake_count\").alias(\"max_earthquakes_per_day\"),\n",
    "        F.avg(\"avg_magnitude\").alias(\"avg_magnitude\")\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2a2a46-9c1c-4149-a29e-40aae83124b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
