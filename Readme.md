markdown
# ğŸŒ DataLake Climat & Risques Naturels  
**Plateforme conteneurisÃ©e d'analyse de donnÃ©es climatiques et gÃ©ologiques**  
*Ingestion, traitement et visualisation de donnÃ©es NOAA et USGS avec Hadoop, Spark et Streamlit*

## ğŸ—ï¸ Structure du Projet
datalake-climate-risks/
â”œâ”€â”€ docker-compose.yml # Configuration Docker
â”œâ”€â”€ frontend/ # Dashboard Streamlit
â”‚ â”œâ”€â”€ Dockerfile.streamlit # Image Docker pour Streamlit
â”‚ â”œâ”€â”€ requirements.txt # DÃ©pendances Python
â”‚ â”œâ”€â”€ app.py # Application principale
â”‚ â”œâ”€â”€ pages/ # Pages du dashboard
â”‚ â”‚ â”œâ”€â”€ 1_ğŸ _Dashboard.py # Page d'accueil
â”‚ â”‚ â”œâ”€â”€ 2_ğŸ“Š_NOAA_Visualisations.py # Visualisations NOAA
â”‚ â”‚ â”œâ”€â”€ 3_ğŸŒ‹_USGS_Visualisations.py # Visualisations USGS
â”‚ â”‚ â”œâ”€â”€ 4_ğŸš¨_Alertes_Temps_RÃ©el.py # Alertes en temps rÃ©el
â”‚ â”‚ â”œâ”€â”€ 5_ğŸ“_Explorer_HDFS.py # Explorateur de donnÃ©es
â”‚ â”‚ â””â”€â”€ 6_âš™ï¸_Administration.py # Administration systÃ¨me
â”‚ â””â”€â”€ utils/ # Utilitaires
â”‚ â”œâ”€â”€ hdfs_client.py # Client HDFS
â”‚ â””â”€â”€ spark_client.py # Client Spark
â”œâ”€â”€ ingestion/ # Scripts d'ingestion
â”‚ â”œâ”€â”€ batch_noaa.py # Ingestion batch NOAA
â”‚ â”œâ”€â”€ batch_usgs.py # Ingestion batch USGS
â”‚ â””â”€â”€ stream_ingest.py # Ingestion streaming
â”œâ”€â”€ spark-jobs/ # Jobs Spark
â”‚ â”œâ”€â”€ etl_cleaning.py # Nettoyage ETL
â”‚ â”œâ”€â”€ daily_aggregation.py # AgrÃ©gations quotidiennes
â”‚ â”œâ”€â”€ detect_anomalies.py # DÃ©tection d'anomalies
â”‚ â””â”€â”€ calculate_trends.py # Calcul des tendances
â”œâ”€â”€ notebooks/ # Notebooks Jupyter
â”‚ â””â”€â”€ development.ipynb # Notebook de dÃ©veloppement
â””â”€â”€ README.md # Documentation


## ğŸš€ DÃ©marrage Rapide

### 1. PrÃ©requis
- **Docker** et **Docker Compose** (Docker Desktop recommandÃ©)
- **4 Go de RAM** minimum, 8 Go recommandÃ©s
- **Git**

### 2. Installation
```bash
# Clonez le dÃ©pÃ´t
git clone <votre-repo>
cd Datalake_Projet

# Lancez tous les services
docker-compose up -d

# Attendez que tous les services soient prÃªts (30-60 secondes)
docker-compose logs -f
3. Initialisation des DonnÃ©es
bash
# Ingestion initiale des donnÃ©es NOAA
docker-compose exec spark spark-submit /app/ingestion/batch_noaa.py

# Ingestion initiale des donnÃ©es USGS
docker-compose exec spark spark-submit /app/ingestion/batch_usgs.py

# Lancement de l'ingestion streaming
docker-compose exec spark spark-submit /app/ingestion/stream_ingest.py
ğŸ–¥ï¸ Services Disponibles
Service	URL	Port	Description
ğŸ“Š Streamlit Dashboard	http://localhost:8501	8501	Interface principale
âš¡ Apache Spark Master	http://localhost:8080	8080	Interface Spark
ğŸ—„ï¸ Hadoop HDFS NameNode	http://localhost:9870	9870	Explorateur HDFS
ğŸ’» Jupyter Lab	http://localhost:8888	8888	Environnement dev
ğŸ”„ Apache Airflow	http://localhost:8080	8080	Orchestration (si configurÃ©)
ğŸ“Š FonctionnalitÃ©s du Dashboard
ğŸ  Page Dashboard
Vue d'ensemble des KPIs climatiques

Carte interactive des risques

Statistiques globales

ğŸ“Š NOAA Visualisations
DonnÃ©es mÃ©tÃ©orologiques historiques

Graphiques de tempÃ©rature et prÃ©cipitations

Tendances climatiques par rÃ©gion

ğŸŒ‹ USGS Visualisations
ActivitÃ© sismique en temps rÃ©el

DonnÃ©es hydrologiques

Surveillance gÃ©ologique

ğŸš¨ Alertes Temps RÃ©el
Alertes NOAA (tempÃªtes, inondations)

Alertes USGS (sÃ©ismes > magnitude 4.5)

Notifications configurables par email

ğŸ“ Explorer HDFS
Navigation dans l'arborescence HDFS

PrÃ©visualisation des fichiers Parquet/CSV

TÃ©lÃ©chargement d'Ã©chantillons

âš™ï¸ Administration
Monitoring des services

Gestion des pipelines ETL

Configuration des sources de donnÃ©es

ğŸ”„ Pipeline de DonnÃ©es
Architecture de traitement
text
Sources externes (NOAA/USGS APIs)
        â†“
Ingestion (batch + streaming)
        â†“
Stockage HDFS (/raw/)
        â†“
Traitement Spark (ETL/agrÃ©gation)
        â†“
Stockage HDFS (/processed/)
        â†“
Visualisation Streamlit
Jobs Spark disponibles
ETL Cleaning (etl_cleaning.py) - Nettoyage des donnÃ©es brutes

Daily Aggregation (daily_aggregation.py) - AgrÃ©gations temporelles

Anomaly Detection (detect_anomalies.py) - DÃ©tection automatique

Trend Analysis (calculate_trends.py) - Analyse des tendances

ğŸ› ï¸ DÃ©veloppement
Ajouter une nouvelle page au dashboard
python
# 1. CrÃ©ez un fichier dans frontend/pages/
# 2. Nommez-le : "7_ğŸ“ˆ_Nouvelle_Analyse.py"
# 3. Structure de base :
import streamlit as st

st.set_page_config(page_title="Nouvelle Analyse")
st.title("ğŸ“ˆ Nouvelle Analyse")
# Votre code ici
ExÃ©cuter un job Spark personnalisÃ©
bash
docker-compose exec spark spark-submit /app/spark-jobs/votre_job.py
AccÃ©der aux notebooks Jupyter
Ouvrez http://localhost:8888

Utilisez le token : jupyter

Les donnÃ©es sont accessibles dans /app/

âš™ï¸ Configuration

# Configuration HDFS
HDFS_NAMENODE=hdfs://namenode:9000
HDFS_USER=datalake_user

# Configuration Spark
SPARK_MASTER=spark://spark-master:7077
Personnaliser les services
Ã‰ditez docker-compose.yml pour :

Ajuster les ressources mÃ©moire/CPU

Modifier les ports exposÃ©s

Ajouter de nouveaux services

ğŸ“ Gestion des DonnÃ©es
Structure HDFS recommandÃ©e
text
/user/datalake/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ noaa/              # DonnÃ©es brutes NOAA
â”‚   â””â”€â”€ usgs/              # DonnÃ©es brutes USGS
â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ noaa/              # DonnÃ©es nettoyÃ©es NOAA
â”‚   â””â”€â”€ usgs/              # DonnÃ©es nettoyÃ©es USGS
â”œâ”€â”€ analytics/             # RÃ©sultats d'analyses
â””â”€â”€ models/               # ModÃ¨les ML entraÃ®nÃ©s
Commandes HDFS utiles
bash
# Lister les fichiers
docker-compose exec namenode hdfs dfs -ls /user/datalake

# CrÃ©er un dossier
docker-compose exec namenode hdfs dfs -mkdir -p /user/datalake/raw/noaa

# Copier des fichiers locaux vers HDFS
docker-compose exec namenode hdfs dfs -put localfile.csv /user/datalake/raw/
ğŸ§¹ Maintenance
Commandes Docker essentielles
bash
# Voir l'Ã©tat des services
docker-compose ps

# Voir les logs
docker-compose logs -f streamlit
docker-compose logs -f spark

# ArrÃªter proprement
docker-compose down

# RedÃ©marrer un service
docker-compose restart spark
Nettoyage
bash
# Supprimer les conteneurs et volumes
docker-compose down -v

# Nettoyer les images non utilisÃ©es
docker system prune -a
âš ï¸ DÃ©pannage
ProblÃ¨me	Solution
Port dÃ©jÃ  utilisÃ©	Modifiez les ports dans docker-compose.yml
HDFS non accessible	docker-compose restart namenode datanode
Spark jobs Ã©chouent	VÃ©rifiez les logs : docker-compose logs spark
Dashboard lent	Augmentez les ressources dans docker-compose.yml
Erreurs d'API	VÃ©rifiez les clÃ©s API dans .env
ğŸ“š Documentation Technique
BibliothÃ¨ques principales
Streamlit : Interface utilisateur

PySpark : Traitement distribuÃ©

HDFS : Stockage distribuÃ©

Pandas/NumPy : Analyse de donnÃ©es

Plotly/Matplotlib : Visualisations

Sources de donnÃ©es
NOAA : https://www.ncdc.noaa.gov/cdo-web/

USGS : https://earthquake.usgs.gov/fdsnws/event/1/

Documentation API : Voir les scripts dans ingestion/

ğŸ“„ Licence
MIT License - Voir le fichier LICENSE pour plus de dÃ©tails.