import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta

st.set_page_config(page_title="USGS Visualisations", page_icon="üåã", layout="wide")

st.title("üåã Visualisations USGS - Donn√©es Sismiques")

st.info("‚ÑπÔ∏è Cette page montre les visualisations d√©taill√©es des donn√©es USGS (United States Geological Survey)")

# Charger les donn√©es USGS
@st.cache_data
def load_usgs_data():
    # G√©n√©rer des donn√©es sismiques simul√©es
    n_events = 200
    regions = ['California', 'Alaska', 'Hawaii', 'Nevada', 'Washington', 'Oregon', 'Utah', 'Montana']
    
    # Coordonn√©es approximatives par r√©gion
    region_coords = {
        'California': (36.7783, -119.4179),
        'Alaska': (64.2008, -149.4937),
        'Hawaii': (19.8968, -155.5828),
        'Nevada': (38.8026, -116.4194),
        'Washington': (47.7511, -120.7401),
        'Oregon': (43.8041, -120.5542),
        'Utah': (39.3210, -111.0937),
        'Montana': (46.8797, -110.3626)
    }
    
    data = []
    for i in range(n_events):
        region = np.random.choice(regions)
        lat, lon = region_coords[region]
        
        # G√©n√©rer des coordonn√©es al√©atoires autour du centre de la r√©gion
        event_lat = lat + np.random.uniform(-2, 2)
        event_lon = lon + np.random.uniform(-2, 2)
        
        # G√©n√©rer une magnitude (distribution exponentielle invers√©e)
        magnitude = np.random.exponential(scale=1.5) + 2.0
        if magnitude > 9.0:
            magnitude = 9.0
        
        # G√©n√©rer une profondeur
        depth = np.random.exponential(scale=20) + 1
        
        # G√©n√©rer un timestamp al√©atoire dans les 30 derniers jours
        days_ago = np.random.uniform(0, 30)
        timestamp = datetime.now() - timedelta(days=days_ago)
        
        data.append({
            'Timestamp': timestamp,
            'Magnitude': round(magnitude, 1),
            'Depth_km': round(depth, 1),
            'Region': region,
            'Latitude': round(event_lat, 4),
            'Longitude': round(event_lon, 4),
            'Day_of_Year': timestamp.timetuple().tm_yday
        })
    
    df = pd.DataFrame(data)
    
    # Cat√©goriser par intensit√©
    df['Intensity'] = pd.cut(df['Magnitude'], 
                            bins=[0, 3, 4, 5, 6, 7, 10],
                            labels=['Tr√®s Faible', 'Faible', 'L√©ger', 'Mod√©r√©', 'Fort', 'Majeur'])
    
    return df

df_usgs = load_usgs_data()

# Afficher les m√©triques principales
st.subheader("üìà M√©triques Globales")

col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("üåã S√©ismes totaux", len(df_usgs))
with col2:
    max_mag = df_usgs['Magnitude'].max()
    st.metric("üìà Magnitude max", f"{max_mag:.1f}")
with col3:
    avg_depth = df_usgs['Depth_km'].mean()
    st.metric("‚¨áÔ∏è Profondeur moyenne", f"{avg_depth:.1f} km")
with col4:
    st.metric("üó∫Ô∏è R√©gions", df_usgs['Region'].nunique())

# Onglets pour diff√©rentes visualisations
tab1, tab2, tab3, tab4 = st.tabs(["üìä Analyses", "üó∫Ô∏è Carte", "üìã Donn√©es", "‚è±Ô∏è √âvolution Temporelle"])

with tab1:
    # Filtres
    st.subheader("üîç Filtres")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        min_magnitude = st.slider(
            "Magnitude minimale",
            float(df_usgs['Magnitude'].min()),
            float(df_usgs['Magnitude'].max()),
            2.5
        )
    
    with col2:
        selected_regions = st.multiselect(
            "S√©lectionner les r√©gions",
            df_usgs['Region'].unique(),
            default=df_usgs['Region'].unique()[:3]
        )
    
    with col3:
        intensity_filter = st.multiselect(
            "Intensit√©",
            df_usgs['Intensity'].unique(),
            default=df_usgs['Intensity'].unique()
        )
    
    # Filtrer les donn√©es
    filtered_df = df_usgs[
        (df_usgs['Magnitude'] >= min_magnitude) &
        (df_usgs['Region'].isin(selected_regions)) &
        (df_usgs['Intensity'].isin(intensity_filter))
    ]
    
    if filtered_df.empty:
        st.warning("‚ö†Ô∏è Aucun s√©isme ne correspond aux filtres s√©lectionn√©s")
    else:
        col1, col2 = st.columns(2)
        
        with col1:
            # Histogramme des magnitudes
            st.markdown("#### üìä Distribution des Magnitudes")
            fig_hist = px.histogram(
                filtered_df,
                x='Magnitude',
                nbins=30,
                color='Region',
                title='Distribution des Magnitudes',
                marginal='box'
            )
            fig_hist.update_layout(height=500)
            st.plotly_chart(fig_hist, use_container_width=True)
        
        with col2:
            # Box plot par r√©gion
            st.markdown("#### üì¶ Magnitudes par R√©gion")
            fig_box = px.box(
                filtered_df,
                x='Region',
                y='Magnitude',
                color='Region',
                title='Comparaison R√©gionale',
                points='all'
            )
            fig_box.update_layout(height=500)
            st.plotly_chart(fig_box, use_container_width=True)
        
        # Scatter plot Magnitude vs Profondeur
        st.markdown("#### üìç Relation Magnitude-Profondeur")
        fig_scatter = px.scatter(
            filtered_df,
            x='Magnitude',
            y='Depth_km',
            color='Region',
            size='Magnitude',
            hover_data=['Timestamp', 'Intensity'],
            title='Magnitude vs Profondeur'
        )
        st.plotly_chart(fig_scatter, use_container_width=True)
        
        # Diagramme de r√©partition
        st.markdown("#### üéØ R√©partition par Intensit√©")
        intensity_counts = filtered_df['Intensity'].value_counts().reset_index()
        intensity_counts.columns = ['Intensit√©', 'Nombre']
        
        fig_pie = px.pie(
            intensity_counts,
            values='Nombre',
            names='Intensit√©',
            title='R√©partition par Niveau d\'Intensit√©',
            color='Intensit√©',
            color_discrete_map={
                'Tr√®s Faible': '#00FF00',
                'Faible': '#7CFC00',
                'L√©ger': '#FFFF00',
                'Mod√©r√©': '#FFA500',
                'Fort': '#FF4500',
                'Majeur': '#FF0000'
            }
        )
        st.plotly_chart(fig_pie, use_container_width=True)

with tab2:
    st.subheader("üó∫Ô∏è Carte Interactive des S√©ismes")
    
    # L√©gende des couleurs
    st.markdown("""
    ### üé® L√©gende des Intensit√©s:
    - üü¢ **Tr√®s Faible** (0-3.0)
    - üü° **Faible** (3.0-4.0)
    - üü† **L√©ger** (4.0-5.0)
    - üî¥ **Mod√©r√©** (5.0-6.0)
    - üü• **Fort** (6.0-7.0)
    - ‚ö´ **Majeur** (7.0+)
    """)
    
    # Filtres pour la carte
    col1, col2 = st.columns(2)
    with col1:
        map_mag_min = st.slider(
            "Filtre magnitude (carte)",
            float(df_usgs['Magnitude'].min()),
            float(df_usgs['Magnitude'].max()),
            3.0
        )
    with col2:
        days_back = st.slider("P√©riode (jours)", 1, 365, 30)
    
    # Filtrer les donn√©es pour la carte
    date_threshold = datetime.now() - timedelta(days=days_back)
    map_data = df_usgs[
        (df_usgs['Magnitude'] >= map_mag_min) &
        (df_usgs['Timestamp'] >= date_threshold)
    ].copy()
    
    if map_data.empty:
        st.warning("‚ö†Ô∏è Aucun s√©isme r√©cent ne correspond aux filtres")
    else:
        # CORRECTION : Pr√©parer les donn√©es pour la carte de mani√®re simple
        # Cr√©er une copie simple des donn√©es n√©cessaires
        map_data_simple = map_data[['Latitude', 'Longitude', 'Magnitude', 'Intensity']].copy()
        
        # Ajouter une colonne de taille proportionnelle √† la magnitude
        map_data_simple['size'] = map_data_simple['Magnitude'].apply(lambda x: min(50, x * 5))
        
        # Mapper les intensit√©s aux couleurs
        color_map_simple = {
            'Tr√®s Faible': '#00FF00',
            'Faible': '#7CFC00',
            'L√©ger': '#FFFF00',
            'Mod√©r√©': '#FFA500',
            'Fort': '#FF4500',
            'Majeur': '#FF0000'
        }
        
        # S'assurer que toutes les intensit√©s ont une couleur
        map_data_simple['color'] = map_data_simple['Intensity'].apply(
            lambda x: color_map_simple.get(str(x), '#808080')
        )
        
        # Afficher la carte SIMPLIFI√âE (sans param√®tres probl√©matiques)
        try:
            st.map(map_data_simple[['Latitude', 'Longitude']].dropna())
        except Exception as e:
            st.error(f"Erreur avec la carte : {str(e)[:100]}")
            # Solution de secours
            st.write("üìä Donn√©es sur la carte :")
            st.dataframe(map_data_simple.head(10))
        
        # Statistiques sur la carte
        st.subheader("üìä Statistiques de la Carte")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("S√©ismes affich√©s", len(map_data))
        with col2:
            st.metric("Magnitude moyenne", f"{map_data['Magnitude'].mean():.1f}")
        with col3:
            st.metric("Dernier s√©isme", map_data['Timestamp'].max().strftime('%Y-%m-%d'))
        with col4:
            st.metric("R√©gions concern√©es", map_data['Region'].nunique())
        
        # Carte de densit√©
        st.subheader("üó∫Ô∏è Carte de Densit√©")
        
        # Cr√©er une heatmap simplifi√©e
        fig_density = px.density_mapbox(
            map_data,
            lat='Latitude',
            lon='Longitude',
            z='Magnitude',
            radius=15,
            center=dict(lat=40, lon=-100),
            zoom=3,
            mapbox_style="carto-positron",
            title='Densit√© des S√©ismes (Magnitude)',
            height=500
        )
        st.plotly_chart(fig_density, use_container_width=True)
        
        # Visualisation 3D
        st.subheader("üõ∏ Visualisation 3D")
        
        fig_3d = px.scatter_3d(
            map_data,
            x='Longitude',
            y='Latitude',
            z='Depth_km',
            color='Magnitude',
            size='Magnitude',
            hover_data=['Region', 'Timestamp', 'Intensity'],
            title='Localisation 3D des S√©ismes',
            height=600
        )
        st.plotly_chart(fig_3d, use_container_width=True)

with tab3:
    st.subheader("üìã Donn√©es Brutes")
    
    # Options d'affichage
    col1, col2, col3 = st.columns(3)
    with col1:
        rows_to_show = st.selectbox("Lignes √† afficher", [10, 25, 50, 100, 200])
    with col2:
        sort_by = st.selectbox("Trier par", ['Timestamp', 'Magnitude', 'Depth_km', 'Region'])
    with col3:
        sort_order = st.radio("Ordre", ['D√©croissant', 'Croissant'], horizontal=True)
    
    # Trier les donn√©es
    ascending = sort_order == 'Croissant'
    sorted_data = df_usgs.sort_values(sort_by, ascending=ascending)
    
    # Afficher les donn√©es
    st.dataframe(
        sorted_data.head(rows_to_show),
        use_container_width=True,
        height=400
    )
    
    # Statistiques par r√©gion
    st.subheader("üìä Statistiques par R√©gion")
    
    region_stats = df_usgs.groupby('Region').agg({
        'Magnitude': ['count', 'mean', 'max', 'min'],
        'Depth_km': ['mean'],
        'Timestamp': ['min', 'max']
    }).round(2)
    
    # Aplatir les colonnes MultiIndex
    region_stats.columns = ['_'.join(col).strip() for col in region_stats.columns.values]
    region_stats = region_stats.reset_index()
    
    st.dataframe(region_stats, use_container_width=True)
    
    # Bouton de t√©l√©chargement
    csv_data = df_usgs.to_csv(index=False)
    st.download_button(
        label="üì• T√©l√©charger les donn√©es (CSV)",
        data=csv_data,
        file_name=f"usgs_earthquakes_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv"
    )

with tab4:
    st.subheader("‚è±Ô∏è √âvolution Temporelle")
    
    # Agr√©gation par jour
    df_usgs['Date'] = df_usgs['Timestamp'].dt.date
    daily_stats = df_usgs.groupby('Date').agg({
        'Magnitude': ['count', 'mean', 'max'],
        'Depth_km': ['mean']
    }).round(2)
    
    # Aplatir les colonnes MultiIndex
    daily_stats.columns = ['_'.join(col).strip() for col in daily_stats.columns.values]
    daily_stats = daily_stats.reset_index()
    
    # Graphique d'√©volution
    fig_evolution = go.Figure()
    
    # Ajouter la courbe du nombre de s√©ismes
    fig_evolution.add_trace(go.Scatter(
        x=daily_stats['Date'],
        y=daily_stats['Magnitude_count'],
        mode='lines+markers',
        name='Nombre de s√©ismes',
        line=dict(color='blue', width=2),
        yaxis='y'
    ))
    
    # Ajouter la courbe de magnitude moyenne
    fig_evolution.add_trace(go.Scatter(
        x=daily_stats['Date'],
        y=daily_stats['Magnitude_mean'],
        mode='lines+markers',
        name='Magnitude moyenne',
        line=dict(color='red', width=2),
        yaxis='y2'
    ))
    
    fig_evolution.update_layout(
        title='√âvolution Journali√®re des S√©ismes',
        xaxis_title='Date',
        yaxis=dict(
            title='Nombre de s√©ismes',
            title_font=dict(color='blue'),
            tickfont=dict(color='blue')
        ),
        yaxis2=dict(
            title='Magnitude moyenne',
            title_font=dict(color='red'),
            tickfont=dict(color='red'),
            overlaying='y',
            side='right'
        ),
        height=500,
        hovermode='x unified'
    )
    
    st.plotly_chart(fig_evolution, use_container_width=True)
    
    # Analyse des patterns
    st.subheader("üîç Analyse des Patterns")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Analyse par jour de la semaine
        df_usgs['Weekday'] = df_usgs['Timestamp'].dt.day_name()
        weekday_counts = df_usgs['Weekday'].value_counts().reindex([
            'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'
        ])
        
        fig_weekday = px.bar(
            x=weekday_counts.index,
            y=weekday_counts.values,
            title='Distribution par Jour de la Semaine',
            labels={'x': 'Jour', 'y': 'Nombre de s√©ismes'},
            color=weekday_counts.values,
            color_continuous_scale='Reds'
        )
        st.plotly_chart(fig_weekday, use_container_width=True)
    
    with col2:
        # Analyse par heure
        df_usgs['Hour'] = df_usgs['Timestamp'].dt.hour
        hourly_counts = df_usgs['Hour'].value_counts().sort_index()
        
        fig_hour = px.bar(
            x=hourly_counts.index,
            y=hourly_counts.values,
            title='Distribution par Heure',
            labels={'x': 'Heure', 'y': 'Nombre de s√©ismes'},
            color=hourly_counts.values,
            color_continuous_scale='Oranges'
        )
        st.plotly_chart(fig_hour, use_container_width=True)
    
    # Corr√©lations
    st.subheader("üìä Matrice de Corr√©lation")
    
    # Utiliser des noms de colonnes simples
    corr_data = df_usgs[['Magnitude', 'Depth_km', 'Day_of_Year', 'Latitude', 'Longitude']].copy()
    
    # Renommer pour plus de clart√©
    corr_data = corr_data.rename(columns={
        'Depth_km': 'Profondeur_km',
        'Day_of_Year': 'Jour_Annee'
    })
    
    corr_matrix = corr_data.corr()
    
    fig_corr = px.imshow(
        corr_matrix,
        text_auto=True,
        aspect='auto',
        color_continuous_scale='RdBu',
        title='Corr√©lations entre Variables'
    )
    st.plotly_chart(fig_corr, use_container_width=True)

# Informations sur les donn√©es
with st.expander("‚ÑπÔ∏è √Ä propos des donn√©es USGS", expanded=False):
    st.markdown("""
    ## üåê Source des donn√©es: USGS (United States Geological Survey)
    
    ### üìä √âchelle de Richter:
    - **0-3.0:** Tr√®s faible - G√©n√©ralement non ressenti
    - **3.0-4.0:** Faible - Ressenti par quelques personnes
    - **4.0-5.0:** L√©ger - Dommages mineurs possibles
    - **5.0-6.0:** Mod√©r√© - Dommages significatifs
    - **6.0-7.0:** Fort - Dommages majeurs
    - **7.0+:** Majeur - Catastrophe r√©gionale
    
    ### üéØ Types de donn√©es collect√©es:
    - **Magnitude** - √ânergie lib√©r√©e
    - **Profondeur** (km) - Foyer sismique
    - **Localisation** - Coordonn√©es GPS
    - **Timestamp** - Date et heure pr√©cise
    - **R√©gion** - Zone g√©ographique
    
    ### üó∫Ô∏è Zones d'√©tude:
    - **√âtats-Unis continentaux**
    - **Alaska** - Zone tr√®s active
    - **Hawaii** - Activit√© volcanique
    - **Ouest des USA** - Faille de San Andreas
    
    ### üîß Qualit√© des donn√©es:
    - **Valid√©es en temps r√©el**
    - **Mises √† jour continues**
    - **Format standardis√©**
    - **Historique complet**
    
    ### üéØ Utilisations principales:
    - √âvaluation des risques sismiques
    - Recherche g√©ologique
    - Planification d'urgence
    - Construction parasismique
    - Alerte pr√©coce
    
    ### ‚ö†Ô∏è Limitations:
    - Donn√©es simul√©es pour cette d√©monstration
    - En production: API USGS temps r√©el
    - D√©lai de traitement: quelques minutes
    - Couverture: mondiale mais focus USA
    """)