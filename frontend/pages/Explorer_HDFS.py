import streamlit as st
from utils.hdfs_client import HDFSClient

st.title("ğŸ“ Explorer HDFS")
st.markdown("### Naviguez dans l'architecture du DataLake")

client = HDFSClient()

if not client.connected:
    st.error("""
    âŒ **HDFS non connectÃ©**
    - VÃ©rifiez que le service HDFS est dÃ©marrÃ©
    - VÃ©rifiez la configuration dans `hdfs_client.py`
    """)
    st.stop()

# Navigation
path = st.text_input("Chemin HDFS", "/hadoop-climate-risk")

if st.button("ğŸ“‚ Lister le contenu") or path:
    with st.spinner(f"Chargement de {path}..."):
        try:
            items = client.list_files(path)
            
            if items:
                # SÃ©parer fichiers et dossiers
                folders = []
                files = []
                
                for item in items:
                    if item.endswith("/"):
                        folders.append(item)
                    else:
                        files.append(item)
                
                # Afficher les dossiers
                st.subheader("ğŸ“‚ Dossiers")
                for folder in folders:
                    col1, col2 = st.columns([6, 1])
                    with col1:
                        st.write(f"ğŸ“ {folder}")
                    with col2:
                        if st.button("Ouvrir", key=f"open_{folder}"):
                            st.session_state.current_path = folder
                            st.rerun()
                
                # Afficher les fichiers
                st.subheader("ğŸ“„ Fichiers")
                for file in files:
                    col1, col2, col3 = st.columns([6, 2, 2])
                    with col1:
                        st.write(f"ğŸ“„ {file.split('/')[-1]}")
                    with col2:
                        if st.button("AperÃ§u", key=f"view_{file}"):
                            try:
                                df = client.read_parquet_head(file, 10)
                                st.dataframe(df)
                            except:
                                st.warning("Format non supportÃ© pour l'aperÃ§u")
                    with col3:
                        if file.endswith(".parquet"):
                            if st.button("TÃ©lÃ©charger", key=f"dl_{file}"):
                                # Logique de tÃ©lÃ©chargement
                                st.info("TÃ©lÃ©chargement simulÃ© - Ã  implÃ©menter")
            else:
                st.info("ğŸ“­ Dossier vide")
                
        except Exception as e:
            st.error(f"Erreur : {e}")

# Structure prÃ©-dÃ©finie
st.markdown("---")
st.subheader("ğŸ—ï¸ Structure standard du DataLake")

structure = {
    "RAW (DonnÃ©es brutes)": [
        "/hadoop-climate-risk/raw/noaa/",
        "/hadoop-climate-risk/raw/usgs/"
    ],
    "SILVER (NettoyÃ©es)": [
        "/hadoop-climate-risk/silver/noaa_cleaned/",
        "/hadoop-climate-risk/silver/usgs_cleaned/"
    ],
    "GOLD (AgrÃ©gÃ©es)": [
        "/hadoop-climate-risk/gold/daily_aggregates/",
        "/hadoop-climate-risk/gold/monthly_trends/"
    ],
    "ALERTES": [
        "/hadoop-climate-risk/alerts/"
    ]
}

for category, paths in structure.items():
    with st.expander(f"**{category}**"):
        for path in paths:
            if st.button(f"ğŸ“‚ Ouvrir {path.split('/')[-2]}", key=path):
                st.session_state.current_path = path
                st.rerun()